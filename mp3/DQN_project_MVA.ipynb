{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wcuGFh5YEcay"
   },
   "source": [
    "**You may need to install [OpenCV](https://pypi.python.org/pypi/opencv-python) and [scikit-video](http://www.scikit-video.org/stable/).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "XH47keutEcaz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "import skvideo.io\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "import random\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential,model_from_json\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import sgd,adam\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Activation, AveragePooling2D,Reshape,BatchNormalization,Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iJUiR263Eca2"
   },
   "source": [
    "# MiniProject #3: Deep Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q_qLO0z-Eca3"
   },
   "source": [
    "__Notations__: $E_p$ is the expectation under probability $p$. Please justify each of your answer and widely comment your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0KZBNVzWEca4"
   },
   "source": [
    "# Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Soa9LzzfEca4"
   },
   "source": [
    "In a reinforcement learning algorithm, we modelize each step $t$ as an action $a_t$ obtained from a state $s_t$, i.e. $\\{(a_{t},s_{t})_{t\\leq T}\\}$ having the Markov property. We consider a discount factor $\\gamma \\in [0,1]$ that ensures convergence. The goal is to find among all the policies $\\pi$, one that maximizes the expected reward:\n",
    "\n",
    "\\begin{equation*}\n",
    "R(\\pi)=\\sum_{t\\leq T}E_{p^{\\pi}}[\\gamma^t r(s_{t},a_{t})] \\> ,\n",
    "\\end{equation*}\n",
    "\n",
    "where: \n",
    "\\begin{equation*}p^{\\pi}(a_{0},a_{1},s_{1},...,a_{T},s_{T})=p(a_{0})\\prod_{t=1}^{T}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "We note the $Q$-function:\n",
    "\n",
    "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "Thus, the optimal Q function is:\n",
    "\\begin{equation*}\n",
    "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "In this project, we will apply the deep reinforcement learning techniques to a simple game: an agent will have to learn from scratch a policy that will permit it maximizing a reward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y_4Yt1XCEca5"
   },
   "source": [
    "## The environment, the agent and the game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TFlN4ZdoEca6"
   },
   "source": [
    "### The environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S6IHdHHQEca6"
   },
   "source": [
    "```Environment``` is an abstract class that represents the states, rewards, and actions to obtain the new state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "tB-px0fvEca7"
   },
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def act(self, act):\n",
    "        \"\"\"\n",
    "        One can act on the environment and obtain its reaction:\n",
    "        - the new state\n",
    "        - the reward of the new state\n",
    "        - should we continue the game?\n",
    "\n",
    "        :return: state, reward, game_over\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Reinitialize the environment to a random state and returns\n",
    "        the original state\n",
    "\n",
    "        :return: state\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def draw(self):\n",
    "        \"\"\"\n",
    "        Visualize in the console or graphically the current state\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BgglTf28Eca9"
   },
   "source": [
    "The method ```act``` allows to act on the environment at a given state $s_t$ (stored internally), via action $a_t$. The method will return the new state $s_{t+1}$, the reward $r(s_{t},a_{t})$ and determines if $t\\leq T$ (*game_over*).\n",
    "\n",
    "The method ```reset``` simply reinitializes the environment to a random state $s_0$.\n",
    "\n",
    "The method ```draw``` displays the current state $s_t$ (this is useful to check the behavior of the Agent).\n",
    "\n",
    "We modelize $s_t$ as a tensor, while $a_t$ is an integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nKZqjCQKEca-"
   },
   "source": [
    "### The Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eCAD0o_uEca_"
   },
   "source": [
    "The goal of the ```Agent``` is to interact with the ```Environment``` by proposing actions $a_t$ obtained from a given state $s_t$ to attempt to maximize its __reward__ $r(s_t,a_t)$. We propose the following abstract class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "WG55CIm7Eca_"
   },
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    def __init__(self, epsilon=0.1, n_action=4):\n",
    "        self.epsilon = epsilon\n",
    "        self.n_action = n_action\n",
    "    \n",
    "    def set_epsilon(self,e):\n",
    "        self.epsilon = e\n",
    "\n",
    "    def act(self,s,train=True):\n",
    "        \"\"\" This function should return the next action to do:\n",
    "        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
    "        if train:\n",
    "            if np.random.rand() <= self.epsilon:\n",
    "                a = np.random.randint(0, self.n_action, size=1)[0]\n",
    "            else:\n",
    "                a = self.learned_act(s)\n",
    "        else: # in some cases, this can improve the performance.. remove it if poor performances\n",
    "            a = self.learned_act(s)\n",
    "\n",
    "        return a\n",
    "\n",
    "    def learned_act(self,s):\n",
    "        \"\"\" Act via the policy of the agent, from a given state s\n",
    "        it proposes an action a\"\"\"\n",
    "        pass\n",
    "\n",
    "    def reinforce(self, s, n_s, a, r, game_over_):\n",
    "        \"\"\" This function is the core of the learning algorithm. \n",
    "        It takes as an input the current state s_, the next state n_s_\n",
    "        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
    "        \n",
    "        Its goal is to learn a policy.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\" This function returns basic stats if applicable: the\n",
    "        loss and/or the model\"\"\"\n",
    "        pass\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\" This function allows to restore a model\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XZ4Fd6bKEcbB"
   },
   "source": [
    "***\n",
    "__Question 1__:\n",
    "Explain the function act. Why is ```epsilon``` essential?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Bsebzp0EcbC"
   },
   "source": [
    "The function act returns the next action that we choose accoding to the policy. It adopts the greedy action with the probability (1-epsilon), and takes random action with the probability epsilon. \n",
    "\n",
    "epsilon is important because this algorithm uses this parameter to control the balance between exploration and exploitation. Big value of epsilon means we consider more about exploration when we act."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zfPk8437EcbC"
   },
   "source": [
    "***\n",
    "### The Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C8VBSPSqEcbD"
   },
   "source": [
    "The ```Agent``` and the ```Environment``` work in an interlaced way as in the following (take some time to understand this code as it is the core of the project)\n",
    "\n",
    "```python\n",
    "\n",
    "epoch = 300\n",
    "env = Environment()\n",
    "agent = Agent()\n",
    "\n",
    "\n",
    "# Number of won games\n",
    "score = 0\n",
    "loss = 0\n",
    "\n",
    "\n",
    "for e in range(epoch):\n",
    "    # At each epoch, we restart to a fresh game and get the initial state\n",
    "    state = env.reset()\n",
    "    # This assumes that the games will end\n",
    "    game_over = False\n",
    "\n",
    "    win = 0\n",
    "    lose = 0\n",
    "    \n",
    "    while not game_over:\n",
    "        # The agent performs an action\n",
    "        action = agent.act(state)\n",
    "\n",
    "        # Apply an action to the environment, get the next state, the reward\n",
    "        # and if the games end\n",
    "        prev_state = state\n",
    "        state, reward, game_over = env.act(action)\n",
    "\n",
    "        # Update the counters\n",
    "        if reward > 0:\n",
    "            win = win + reward\n",
    "        if reward < 0:\n",
    "            lose = lose -reward\n",
    "\n",
    "        # Apply the reinforcement strategy\n",
    "        loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "    # Save as a mp4\n",
    "    if e % 10 == 0:\n",
    "        env.draw(e)\n",
    "\n",
    "    # Update stats\n",
    "    score += win-lose\n",
    "\n",
    "    print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "          .format(e, epoch, loss, win, lose, win-lose))\n",
    "    agent.save()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lEAV1NviEcbE"
   },
   "source": [
    "# The game, *eat cheese*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hBRJwlcvEcbG"
   },
   "source": [
    "A rat runs on an island and tries to eat as much as possible. The island is subdivided into $N\\times N$ cells, in which there are cheese (+0.5) and poisonous cells (-1). The rat has a visibility of 2 cells (thus it can see $5^2$ cells). The rat is given a time $T$ to accumulate as much food as possible. It can perform 4 actions: going up, down, left, right. \n",
    "\n",
    "The goal is to code an agent to solve this task that will learn by trial and error. We propose the following environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ZqK64JjyEcbH"
   },
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
    "        grid_size = grid_size+4\n",
    "        self.grid_size = grid_size\n",
    "        self.max_time = max_time\n",
    "        self.temperature = temperature\n",
    "\n",
    "        #board on which one plays\n",
    "        self.board = np.zeros((grid_size,grid_size))\n",
    "        self.position = np.zeros((grid_size,grid_size))\n",
    "\n",
    "        # coordinate of the cat\n",
    "        self.x = 0\n",
    "        self.y = 1\n",
    "\n",
    "        # self time\n",
    "        self.t = 0\n",
    "\n",
    "        self.scale=16\n",
    "\n",
    "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "    def draw(self,e):\n",
    "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
    "\n",
    "    def get_frame(self,t):\n",
    "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
    "        b[self.board>0,0] = 256\n",
    "        b[self.board < 0, 2] = 256\n",
    "        b[self.x,self.y,:]=256\n",
    "        b[-2:,:,:]=0\n",
    "        b[:,-2:,:]=0\n",
    "        b[:2,:,:]=0\n",
    "        b[:,:2,:]=0\n",
    "        \n",
    "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        self.to_draw[t,:,:,:]=b\n",
    "\n",
    "\n",
    "    def act(self, action):\n",
    "        \"\"\"This function returns the new state, reward and decides if the\n",
    "        game ends.\"\"\"\n",
    "\n",
    "        self.get_frame(int(self.t))\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "\n",
    "        self.position[self.x, self.y] = 1\n",
    "        if action == 0:\n",
    "            if self.x == self.grid_size-3:\n",
    "                self.x = self.x-1\n",
    "            else:\n",
    "                self.x = self.x + 1\n",
    "        elif action == 1:\n",
    "            if self.x == 2:\n",
    "                self.x = self.x+1\n",
    "            else:\n",
    "                self.x = self.x-1\n",
    "        elif action == 2:\n",
    "            if self.y == self.grid_size - 3:\n",
    "                self.y = self.y - 1\n",
    "            else:\n",
    "                self.y = self.y + 1\n",
    "        elif action == 3:\n",
    "            if self.y == 2:\n",
    "                self.y = self.y + 1\n",
    "            else:\n",
    "                self.y = self.y - 1\n",
    "        else:\n",
    "            RuntimeError('Error: action not recognized')\n",
    "\n",
    "        self.t = self.t + 1\n",
    "        reward = self.board[self.x, self.y]\n",
    "        self.board[self.x, self.y] = 0\n",
    "        game_over = self.t > self.max_time\n",
    "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
    "\n",
    "        return state, reward, game_over\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
    "\n",
    "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "\n",
    "\n",
    "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
    "\n",
    "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
    "\n",
    "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "        malus[bonus>0]=0\n",
    "\n",
    "        self.board = bonus + malus\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.board[self.x,self.y] = 0\n",
    "        self.t = 0\n",
    "\n",
    "        state = np.concatenate((\n",
    "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "\n",
    "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H651Tza6EcbL"
   },
   "source": [
    "The following elements are important because they correspond to the hyper parameters for this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "vNQ89gB1EcbL"
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "size = 13\n",
    "T=200\n",
    "temperature=0.3\n",
    "epochs_train=20 # set small when debugging\n",
    "epochs_test=10 # set small when debugging\n",
    "\n",
    "# display videos\n",
    "def display_videos(name):\n",
    "    video = io.open(name, 'r+b').read()\n",
    "    encoded = base64.b64encode(video)\n",
    "    return '''<video alt=\"test\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MCtmcR4jEcbP"
   },
   "source": [
    "__Question 2__ Explain the use of the arrays ```position``` and ```board```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4VKJOlJfEcbQ"
   },
   "source": [
    "The array position records the position of the agent. The array board shows the reward for each position on the board."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kmdHmmmQEcbQ"
   },
   "source": [
    "## Random Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CioZEIIbEcbR"
   },
   "source": [
    "***\n",
    "__Question 3__ Implement a random Agent (only ```learned_act``` needs to be implemented):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "buuCuaJKEcbS"
   },
   "outputs": [],
   "source": [
    "class RandomAgent(Agent):\n",
    "    def __init__(self):\n",
    "        super(RandomAgent, self).__init__()\n",
    "        pass\n",
    "\n",
    "    def learned_act(self, s):\n",
    "        return np.random.randint(0, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "np84slw7EcbT"
   },
   "source": [
    "***\n",
    "***\n",
    "__Question 4__ Visualize the game moves. You need to fill in the following function for the evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "KsgaD7m0EcbU"
   },
   "outputs": [],
   "source": [
    "def test(agent,env,epochs,prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "        \n",
    "    for e in range(epochs):\n",
    "        \n",
    "    # restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "\n",
    "        while not game_over:\n",
    "        # The agent performs an action\n",
    "            action = agent.act(state)\n",
    "\n",
    "        # Apply an action to the environment, get the next state, the reward\n",
    "        # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action)\n",
    "\n",
    "        # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose -reward\n",
    "\n",
    "        # Apply the reinforcement strategy\n",
    "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "       \n",
    "        \n",
    "        # Save as a mp4\n",
    "        env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score = score + win-lose\n",
    "\n",
    "        print(\"Win/lose count {}/{}. Average score ({})\"\n",
    "              .format(win, lose, score/(1+e)))\n",
    "    print('Final score: '+str(score/epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "thM5259qEcbW",
    "outputId": "a7349c03-2424-46d6-c84b-421a6040b93a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win/lose count 8.0/14.0. Average score (-6.0)\n",
      "Win/lose count 10.0/11.0. Average score (-3.5)\n",
      "Win/lose count 7.5/9.0. Average score (-2.8333333333333335)\n",
      "Win/lose count 9.0/10.0. Average score (-2.375)\n",
      "Win/lose count 13.0/14.0. Average score (-2.1)\n",
      "Win/lose count 7.5/10.0. Average score (-2.1666666666666665)\n",
      "Win/lose count 9.5/8.0. Average score (-1.6428571428571428)\n",
      "Win/lose count 8.0/11.0. Average score (-1.8125)\n",
      "Win/lose count 9.0/7.0. Average score (-1.3888888888888888)\n",
      "Win/lose count 9.5/13.0. Average score (-1.6)\n",
      "Final score: -1.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the game\n",
    "env = Environment(grid_size=size, max_time=T,temperature=temperature)\n",
    "\n",
    "# Initialize the agent!\n",
    "agent = RandomAgent()\n",
    "\n",
    "test(agent,env,epochs_test,prefix='random')\n",
    "HTML(display_videos('random0.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IiNVY7C3EcbY"
   },
   "source": [
    "***\n",
    "## DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cEj5Ay7iEcbZ"
   },
   "source": [
    "Let us assume here that $T=\\infty$.\n",
    "\n",
    "***\n",
    "__Question 5__ Let $\\pi$ be a policy, show that:\n",
    "\n",
    "\\begin{equation*}\n",
    "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
    "\\end{equation*}\n",
    "\n",
    "Then, show that for the optimal policy $\\pi^*$ (we assume its existence), the following holds: \n",
    "\n",
    "\\begin{equation*}\n",
    "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
    "\\end{equation*}\n",
    "Finally, deduce that a plausible objective is:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
    "\\end{equation*}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9OGCIKNJEcbZ"
   },
   "source": [
    "\n",
    "__Proof:__   \n",
    "__(1)__  \n",
    "If the sequence of rewards received after time step t is denoted $R_{t+1},R_{t+2},R_{t+3}, ...$. The agent tries to select actions so that the sum of the discounted rewards it receives over the future is maximized. Suppose it chooses $A_t$ to maximize the expected discounted return:\n",
    "\n",
    "\\begin{equation*}\n",
    "G_{t}=R_{t+1}+ \\gamma R_{t+2}+ \\gamma^2 R_{t+3} +... = \\sum^\\infty_{k=0} \\gamma^k R_{t+k+1}\n",
    "\\end{equation*}\n",
    "where $ \\gamma $ is a parameter,$0 \\leq \\gamma \\leq 1$, called the discount rate\n",
    "\n",
    "we deﬁne the value of a state s under a policy $ \\pi $, denoted $ V_\\pi(s, a) $, is the expected return when starting in s and following policy $ \\pi $:\n",
    "\n",
    "\\begin{equation*}\n",
    "V_\\pi(s)= E_{\\pi}[G_t｜S_t=s] =E_{\\pi}[\\sum^\\infty_{k=0} \\gamma^k R_{t+k+1} | S_t=s]\n",
    "\\end{equation*}\n",
    "\n",
    "the value of taking action a in state s under a policy $ \\pi $,  denoted  $ Q_\\pi(s, a) $, as the expected return starting from s, taking the action a, and following policy $ \\pi $:\n",
    "\n",
    "\\begin{align*}\n",
    "Q_\\pi(s,a)&= E_{\\pi}[G_t｜S_t=s,A_t=a] \\\\\n",
    "&= E_{\\pi}[\\sum^\\infty_{k=0} \\gamma^k R_{t+k+1} | S_t=s,A_t=a]\\\\\n",
    "&= E_{\\pi}[ R_{t+1} +\\sum^\\infty_{k=1} \\gamma^k R_{t+k+1} | S_t=s,A_t=a]\\\\\n",
    "&= E_{\\pi}[ r(s,a) +\\gamma E_{\\pi}[G_t｜S_{t+1}=s',A_{t+1}=a']]\\\\\n",
    "&= E_{\\pi}[ r(s,a) +\\gamma Q_\\pi(s',a')]\n",
    "\\end{align*}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8n4zR1N0JhpE"
   },
   "source": [
    "__(2)__  \n",
    "For the optimal policy,  \n",
    "\\begin{align*}\n",
    "V^*(s) &= max_\\pi V_\\pi(s)\\\\\n",
    "Q^*(s,a) &= Q_\\pi(s,a)\n",
    "\\end{align*}\n",
    "\n",
    "Then we can write Q^*(s,a) as follows:  \n",
    "\\begin{equation*}\n",
    "Q^*(s,a) = E_{\\pi}[ r(s,a) + V^*(s_{t+1})| S_t=s,A_t=a])\n",
    "\\end{equation*}\n",
    "\n",
    "The Bellman optimality equation denotes that the value of a state under an optimal policy must equal the expected return for the best action from that state:  \n",
    "\\begin{equation*}\n",
    "V^*(s) = max_a Q^*(s,a)\n",
    "\\end{equation*}\n",
    "So we get  \n",
    "\\begin{equation*}\n",
    "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lvXyqT-FJovB"
   },
   "source": [
    "__(3)__  \n",
    "In deep Q learning, we take $ r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a') $ as the target, and use \"mse\" loss, so the objective loss function can be written as:  \n",
    "\\begin{equation*}\n",
    "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LJ8RNV08Ecba"
   },
   "source": [
    "***\n",
    "The DQN-learning algorithm relies on these derivations to train the parameters $\\theta$ of a Deep Neural Network:\n",
    "\n",
    "1. At the state $s_t$, select the action $a_t$ with best reward using $Q_t$ and store the results;\n",
    "\n",
    "2. Obtain the new state $s_{t+1}$ from the environment $p$;\n",
    "\n",
    "3. Store $(s_t,a_t,s_{t+1})$;\n",
    "\n",
    "4. Obtain $Q_{t+1}$ by minimizing  $\\mathcal{L}$ from a recovered batch from the previously stored results.\n",
    "\n",
    "***\n",
    "__Question 6__ Implement the class ```Memory``` that stores moves (in a replay buffer) via ```remember``` and provides a ```random_access``` to these. Specify a maximum memory size to avoid side effects. You can for example use a ```list()``` and set by default ```max_memory=100```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "XN-rRSjpEcba"
   },
   "outputs": [],
   "source": [
    "class Memory(object):\n",
    "    def __init__(self, max_memory=100):\n",
    "        self.max_memory = max_memory\n",
    "        self.memory = list()\n",
    "\n",
    "    def remember(self, m):\n",
    "        if len(self.memory)<self.max_memory:\n",
    "            self.memory.append(m)\n",
    "        else:\n",
    "            self.memory.pop(0)\n",
    "            self.memory.append(m)\n",
    "\n",
    "    def random_access(self):\n",
    "        return random.choice(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L8QkHyVVEcbd"
   },
   "source": [
    "***\n",
    "The pipeline we will use for training is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "kRHize0YEcbe"
   },
   "outputs": [],
   "source": [
    "def train(agent,env,epoch,prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "    loss = 0\n",
    "\n",
    "    for e in range(epoch):\n",
    "        # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "        # This assumes that the games will terminate\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "\n",
    "        while not game_over:\n",
    "            # The agent performs an action\n",
    "            action = agent.act(state)\n",
    "\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose -reward\n",
    "\n",
    "            # Apply the reinforcement strategy\n",
    "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "        # Save as a mp4\n",
    "        if e % 10 == 0:\n",
    "            env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score += win-lose\n",
    "\n",
    "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "              .format(e, epoch, loss, win, lose, win-lose))\n",
    "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pYf9YBxjEcbh"
   },
   "source": [
    "***\n",
    "__Question 7__ Implement the DQN training algorithm using a cascade of fully connected layers. You can use different learning rate, batch size or memory size parameters. In particular, the loss might oscillate while the player will start to win the games. You have to find a good criterium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "-GEsjF5ZEcbh"
   },
   "outputs": [],
   "source": [
    "class DQN(Agent):\n",
    "    def __init__(self, grid_size,  epsilon = 0.1, memory_size=100, batch_size = 16,n_state=2):\n",
    "        super(DQN, self).__init__(epsilon = epsilon)\n",
    "\n",
    "        # Discount for Q learning\n",
    "        self.discount = 0.99\n",
    "        \n",
    "        self.grid_size = grid_size\n",
    "        \n",
    "        # number of state\n",
    "        self.n_state = n_state\n",
    "\n",
    "        # Memory\n",
    "        self.memory = Memory(memory_size)\n",
    "        \n",
    "        # Batch size when learning\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def learned_act(self, s):\n",
    "        state = s.reshape(-1,5,5,self.n_state)\n",
    "        actions_value = self.model.predict(state)\n",
    "        \n",
    "        action = np.argmax(actions_value[0])\n",
    "        return action\n",
    "\n",
    "    def reinforce(self, s_, n_s_, a_, r_, game_over_):\n",
    "        # Two steps: first memorize the states, second learn from the pool\n",
    "\n",
    "        self.memory.remember([s_, n_s_, a_, r_, game_over_])\n",
    "        \n",
    "        input_states = np.zeros((self.batch_size, 5,5,self.n_state))\n",
    "        target_q = np.zeros((self.batch_size, 4))\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            random_mem = self.memory.random_access()\n",
    "            state = random_mem[1].reshape(-1,5,5,self.n_state)\n",
    "            values_tp = self.model.predict(state)\n",
    "            input_states[i] = random_mem[0]\n",
    "            target_q[i] = values_tp[0]\n",
    "            target_q[i][random_mem[2]] = random_mem[3] + (1 - random_mem[4])*self.discount*np.max(values_tp[0])\n",
    "        ######## FILL IN\n",
    "        # HINT: Clip the target to avoid exploiding gradients.. -- clipping is a bit tighter\n",
    "        target_q = np.clip(target_q, -3, 3)\n",
    "\n",
    "        l = self.model.train_on_batch(input_states, target_q)\n",
    "\n",
    "\n",
    "        return l\n",
    "\n",
    "    def save(self,name_weights='model.h5',name_model='model.json'):\n",
    "        self.model.save_weights(name_weights, overwrite=True)\n",
    "        with open(name_model, \"w\") as outfile:\n",
    "            json.dump(self.model.to_json(), outfile)\n",
    "            \n",
    "    def load(self,name_weights='model.h5',name_model='model.json'):\n",
    "        with open(name_model, \"r\") as jfile:\n",
    "            model = model_from_json(json.load(jfile))\n",
    "        model.load_weights(name_weights)\n",
    "        model.compile(\"sgd\", \"mse\")\n",
    "        self.model = model\n",
    "\n",
    "            \n",
    "class DQN_FC(DQN):\n",
    "    def __init__(self, *args, lr=0.1,**kwargs):\n",
    "        super(DQN_FC, self).__init__( *args,**kwargs)\n",
    "        \n",
    "        # NN Model\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Flatten(input_shape=(5,5,self.n_state)))\n",
    "        model.add(Dense(512, activation='relu'))\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "        model.add(Dense(4, activation='linear'))\n",
    "        \n",
    "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
    "        self.model = model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 511
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "MNvL68BeEcbj",
    "outputId": "db67c240-3c95-455f-b1dc-16738b32362d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000/020 | Loss 0.0049 | Win/lose count 2.5/4.0 (-1.5)\n",
      "Epoch 001/020 | Loss 0.0091 | Win/lose count 4.0/3.0 (1.0)\n",
      "Epoch 002/020 | Loss 0.0062 | Win/lose count 5.5/8.0 (-2.5)\n",
      "Epoch 003/020 | Loss 0.0688 | Win/lose count 3.5/1.0 (2.5)\n",
      "Epoch 004/020 | Loss 0.0591 | Win/lose count 5.5/3.0 (2.5)\n",
      "Epoch 005/020 | Loss 0.0446 | Win/lose count 4.5/4.0 (0.5)\n",
      "Epoch 006/020 | Loss 0.0068 | Win/lose count 3.5/1.0 (2.5)\n",
      "Epoch 007/020 | Loss 0.0324 | Win/lose count 2.0/1.0 (1.0)\n",
      "Epoch 008/020 | Loss 0.0067 | Win/lose count 3.5/6.0 (-2.5)\n",
      "Epoch 009/020 | Loss 0.0041 | Win/lose count 4.5/1.0 (3.5)\n",
      "Epoch 010/020 | Loss 0.0042 | Win/lose count 3.0/0 (3.0)\n",
      "Epoch 011/020 | Loss 0.0476 | Win/lose count 6.5/2.0 (4.5)\n",
      "Epoch 012/020 | Loss 0.0100 | Win/lose count 6.0/5.0 (1.0)\n",
      "Epoch 013/020 | Loss 0.0085 | Win/lose count 5.0/0 (5.0)\n",
      "Epoch 014/020 | Loss 0.0031 | Win/lose count 6.0/4.0 (2.0)\n",
      "Epoch 015/020 | Loss 0.0102 | Win/lose count 4.0/4.0 (0.0)\n",
      "Epoch 016/020 | Loss 0.0107 | Win/lose count 4.0/3.0 (1.0)\n",
      "Epoch 017/020 | Loss 0.0048 | Win/lose count 5.0/8.0 (-3.0)\n",
      "Epoch 018/020 | Loss 0.0166 | Win/lose count 3.5/4.0 (-0.5)\n",
      "Epoch 019/020 | Loss 0.0043 | Win/lose count 5.5/2.0 (3.5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
    "agent = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "train(agent, env, epochs_train, prefix='fc_train')\n",
    "HTML(display_videos('fc_train10.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tagR0shKEcbl"
   },
   "source": [
    "***\n",
    "***\n",
    "__Question 8__ Implement the DQN training algorithm using a CNN (for example, 2 convolutional layers and one final fully connected layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "4nm5bt3HEcbm"
   },
   "outputs": [],
   "source": [
    "class DQN_CNN(DQN):\n",
    "    def __init__(self, *args,lr=0.1,**kwargs):\n",
    "        super(DQN_CNN, self).__init__(*args,**kwargs)\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Convolution2D(filters=32,nb_row=3,nb_col=3, activation='relu',padding='same',input_shape=(5,5,self.n_state)))\n",
    "        model.add(Convolution2D(filters=64,nb_row=3,nb_col=3, activation='relu',padding='same',input_shape=(5,5,self.n_state)))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dense(4, activation='linear'))\n",
    "        \n",
    "        #print(model.summary())\n",
    "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
    "        self.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 905
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "gqgPMH34Ecbn",
    "outputId": "468f4349-7bd5-4282-a794-d3729c6b78a0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(3, 3), activation=\"relu\", input_shape=(5, 5, 2), padding=\"same\", filters=32)`\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(3, 3), activation=\"relu\", input_shape=(5, 5, 2), padding=\"same\", filters=64)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_44 (Conv2D)           (None, 5, 5, 32)          608       \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 5, 5, 64)          18496     \n",
      "_________________________________________________________________\n",
      "flatten_26 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 224,548\n",
      "Trainable params: 224,548\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 000/050 | Loss 0.0037 | Win/lose count 7.5/5.0 (2.5)\n",
      "Epoch 001/050 | Loss 0.0049 | Win/lose count 10.5/8.0 (2.5)\n",
      "Epoch 002/050 | Loss 0.0046 | Win/lose count 4.0/3.0 (1.0)\n",
      "Epoch 003/050 | Loss 0.0524 | Win/lose count 16.5/11.0 (5.5)\n",
      "Epoch 004/050 | Loss 0.0138 | Win/lose count 7.5/11.0 (-3.5)\n",
      "Epoch 005/050 | Loss 0.0149 | Win/lose count 10.0/5.0 (5.0)\n",
      "Epoch 006/050 | Loss 0.0801 | Win/lose count 6.5/6.0 (0.5)\n",
      "Epoch 007/050 | Loss 0.0033 | Win/lose count 8.5/3.0 (5.5)\n",
      "Epoch 008/050 | Loss 0.0164 | Win/lose count 10.0/8.0 (2.0)\n",
      "Epoch 009/050 | Loss 0.0075 | Win/lose count 9.0/5.0 (4.0)\n",
      "Epoch 010/050 | Loss 0.0564 | Win/lose count 9.5/6.0 (3.5)\n",
      "Epoch 011/050 | Loss 0.0121 | Win/lose count 16.5/10.0 (6.5)\n",
      "Epoch 012/050 | Loss 0.0049 | Win/lose count 10.5/6.0 (4.5)\n",
      "Epoch 013/050 | Loss 0.0905 | Win/lose count 9.0/6.0 (3.0)\n",
      "Epoch 014/050 | Loss 0.0193 | Win/lose count 12.5/5.0 (7.5)\n",
      "Epoch 015/050 | Loss 0.0679 | Win/lose count 15.0/5.0 (10.0)\n",
      "Epoch 016/050 | Loss 0.0191 | Win/lose count 19.5/7.0 (12.5)\n",
      "Epoch 017/050 | Loss 0.0029 | Win/lose count 8.5/4.0 (4.5)\n",
      "Epoch 018/050 | Loss 0.0036 | Win/lose count 12.5/6.0 (6.5)\n",
      "Epoch 019/050 | Loss 0.0118 | Win/lose count 12.5/15.0 (-2.5)\n",
      "Epoch 020/050 | Loss 0.0568 | Win/lose count 15.5/11.0 (4.5)\n",
      "Epoch 021/050 | Loss 0.0112 | Win/lose count 11.5/12.0 (-0.5)\n",
      "Epoch 022/050 | Loss 0.0071 | Win/lose count 17.0/6.0 (11.0)\n",
      "Epoch 023/050 | Loss 0.0107 | Win/lose count 10.0/5.0 (5.0)\n",
      "Epoch 024/050 | Loss 0.0591 | Win/lose count 12.5/8.0 (4.5)\n",
      "Epoch 025/050 | Loss 0.0096 | Win/lose count 14.0/9.0 (5.0)\n",
      "Epoch 026/050 | Loss 0.0048 | Win/lose count 13.0/9.0 (4.0)\n",
      "Epoch 027/050 | Loss 0.0113 | Win/lose count 7.5/11.0 (-3.5)\n",
      "Epoch 028/050 | Loss 0.0051 | Win/lose count 20.0/5.0 (15.0)\n",
      "Epoch 029/050 | Loss 0.0219 | Win/lose count 12.5/6.0 (6.5)\n",
      "Epoch 030/050 | Loss 0.0094 | Win/lose count 16.5/7.0 (9.5)\n",
      "Epoch 031/050 | Loss 0.0092 | Win/lose count 13.0/4.0 (9.0)\n",
      "Epoch 032/050 | Loss 0.0692 | Win/lose count 12.0/5.0 (7.0)\n",
      "Epoch 033/050 | Loss 0.0194 | Win/lose count 9.5/7.0 (2.5)\n",
      "Epoch 034/050 | Loss 0.0137 | Win/lose count 11.5/3.0 (8.5)\n",
      "Epoch 035/050 | Loss 0.0630 | Win/lose count 12.5/5.0 (7.5)\n",
      "Epoch 036/050 | Loss 0.0097 | Win/lose count 12.5/5.0 (7.5)\n",
      "Epoch 037/050 | Loss 0.0022 | Win/lose count 13.5/7.0 (6.5)\n",
      "Epoch 038/050 | Loss 0.0046 | Win/lose count 10.0/7.0 (3.0)\n",
      "Epoch 039/050 | Loss 0.0167 | Win/lose count 15.5/6.0 (9.5)\n",
      "Epoch 040/050 | Loss 0.0081 | Win/lose count 9.5/2.0 (7.5)\n",
      "Epoch 041/050 | Loss 0.0091 | Win/lose count 10.5/8.0 (2.5)\n",
      "Epoch 042/050 | Loss 0.0664 | Win/lose count 6.0/4.0 (2.0)\n",
      "Epoch 043/050 | Loss 0.0106 | Win/lose count 10.5/10.0 (0.5)\n",
      "Epoch 044/050 | Loss 0.0657 | Win/lose count 15.5/9.0 (6.5)\n",
      "Epoch 045/050 | Loss 0.0189 | Win/lose count 14.0/5.0 (9.0)\n",
      "Epoch 046/050 | Loss 0.0092 | Win/lose count 13.0/7.0 (6.0)\n",
      "Epoch 047/050 | Loss 0.0037 | Win/lose count 21.0/6.0 (15.0)\n",
      "Epoch 048/050 | Loss 0.0194 | Win/lose count 16.0/7.0 (9.0)\n",
      "Epoch 049/050 | Loss 0.0161 | Win/lose count 25.5/8.0 (17.5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_train = 50\n",
    "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
    "agent = DQN_CNN(size, lr=.1, epsilon = 0.3, memory_size=2000, batch_size = 32)\n",
    "train(agent,env,epochs_train,prefix='cnn_train')\n",
    "HTML(display_videos('cnn_train40.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xw5fbMqhEcbp"
   },
   "source": [
    "***\n",
    "***\n",
    "__Question 9__ Test both algorithms and compare their performances. Which issue(s) do you observe? Observe also different behaviors by changing the temperature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YZbOTGxBaaF9"
   },
   "source": [
    "Issue: With both algorithms, the player tends to be stuck somewhere and does not show obvious trend to explore.\n",
    "\n",
    "With bigger value of temperature,  there are more 'postive reward' position and 'negative reward' positions in the grid, and this issue seems to be alleviated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "aZT5H00MEcbp",
    "outputId": "6eb18aad-3421-413f-bb24-b0e0d2ff619b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(3, 3), activation=\"relu\", input_shape=(5, 5, 2), padding=\"same\", filters=32)`\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(3, 3), activation=\"relu\", input_shape=(5, 5, 2), padding=\"same\", filters=64)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 5, 5, 32)          608       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 5, 5, 64)          18496     \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 224,548\n",
      "Trainable params: 224,548\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Test of the CNN\n",
      "Win/lose count 13.5/3.0. Average score (10.5)\n",
      "Win/lose count 12.5/5.0. Average score (9.0)\n",
      "Win/lose count 7.0/2.0. Average score (7.666666666666667)\n",
      "Win/lose count 5.5/4.0. Average score (6.125)\n",
      "Win/lose count 8.0/9.0. Average score (4.7)\n",
      "Win/lose count 6.5/4.0. Average score (4.333333333333333)\n",
      "Win/lose count 9.5/4.0. Average score (4.5)\n",
      "Win/lose count 4.0/1.0. Average score (4.3125)\n",
      "Win/lose count 5.5/0. Average score (4.444444444444445)\n",
      "Win/lose count 6.0/2.0. Average score (4.4)\n",
      "Final score: 4.4\n",
      "Test of the FC\n",
      "Win/lose count 3.5/2.0. Average score (1.5)\n",
      "Win/lose count 3.5/6.0. Average score (-0.5)\n",
      "Win/lose count 5.0/7.0. Average score (-1.0)\n",
      "Win/lose count 7.0/4.0. Average score (0.0)\n",
      "Win/lose count 2.0/4.0. Average score (-0.4)\n",
      "Win/lose count 4.0/4.0. Average score (-0.3333333333333333)\n",
      "Win/lose count 6.5/6.0. Average score (-0.21428571428571427)\n",
      "Win/lose count 5.5/3.0. Average score (0.125)\n",
      "Win/lose count 10.5/5.0. Average score (0.7222222222222222)\n",
      "Win/lose count 9.0/7.0. Average score (0.85)\n",
      "Final score: 0.85\n"
     ]
    }
   ],
   "source": [
    "#epochs_train = 20\n",
    "env = Environment(grid_size=size, max_time=T,temperature=0.5)\n",
    "agent_cnn = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "agent_cnn.load(name_weights='cnn_trainmodel.h5',name_model='cnn_trainmodel.json')\n",
    "\n",
    "agent_fc = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "agent_cnn.load(name_weights='fc_trainmodel.h5',name_model='fc_trainmodel.json')\n",
    "print('Test of the CNN')\n",
    "test(agent_cnn,env,epochs_test,prefix='cnn_test')\n",
    "print('Test of the FC')\n",
    "test(agent_fc,env,epochs_test,prefix='fc_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "zSKCgOeBEcbr",
    "outputId": "1ebd4108-0d1b-4c77-eb56-afbc605ce021"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(display_videos('cnn_test9.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "GAUKTxXuEcbt",
    "outputId": "a1a63c97-935b-4e2a-a253-a5ca413bf301"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(display_videos('fc_test9.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z6XOYlO0Ecbv"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-TIV4vEYEcbv"
   },
   "source": [
    "***\n",
    "\n",
    "The algorithm tends to not explore the map which can be an issue. We propose two ideas in order to encourage exploration:\n",
    "1. Incorporating a decreasing $\\epsilon$-greedy exploration. You can use the method ```set_epsilon```\n",
    "2. Append via the environment a new state that describes if a cell has been visited or not\n",
    "\n",
    "***\n",
    "__Question 10__ Design a new ```train_explore``` function and environment class ```EnvironmentExploring``` to tackle the issue of exploration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "K3x2-_PZEcbw"
   },
   "outputs": [],
   "source": [
    "def train_explore(agent,env,epoch,prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "    loss = 0\n",
    "\n",
    "    for e in range(epoch):\n",
    "        # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "        # This assumes that the games will terminate\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "\n",
    "        while not game_over:\n",
    "            # The agent performs an action\n",
    "            action = agent.act(state)\n",
    "            agent.set_epsilon(0.95*agent.epsilon)\n",
    "\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, reward_game, game_over = env.act(action, train=True)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward_game\n",
    "            if reward < 0:\n",
    "                lose = lose -reward_game\n",
    "\n",
    "            # Apply the reinforcement strategy\n",
    "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "        # Save as a mp4\n",
    "        if e % 10 == 0:\n",
    "            env.draw(prefix+str(e))\n",
    "            agent.set_epsilon(np.fmax(0.05,agent.epsilon/2.))\n",
    "\n",
    "        # Update stats\n",
    "        score += win-lose\n",
    "\n",
    "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "              .format(e, epoch, loss, win, lose, win-lose))\n",
    "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')\n",
    "        \n",
    "class EnvironmentExploring(object):\n",
    "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
    "        grid_size = grid_size+4\n",
    "        self.grid_size = grid_size\n",
    "        self.max_time = max_time\n",
    "        self.temperature = temperature\n",
    "\n",
    "        #board on which one plays\n",
    "        self.board = np.zeros((grid_size,grid_size))\n",
    "        self.position = np.zeros((grid_size,grid_size))\n",
    "        self.malus_position = np.zeros((grid_size,grid_size))\n",
    "        # coordinate of the cat\n",
    "        self.x = 0\n",
    "        self.y = 1\n",
    "\n",
    "        # self time\n",
    "        self.t = 0\n",
    "\n",
    "        self.scale=16\n",
    "\n",
    "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "    def draw(self,e):\n",
    "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
    "\n",
    "    def get_frame(self,t):\n",
    "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
    "        b[self.board>0,0] = 256\n",
    "        b[self.board < 0, 2] = 256\n",
    "        b[self.x,self.y,:]=256\n",
    "        b[-2:,:,:]=0\n",
    "        b[:,-2:,:]=0\n",
    "        b[:2,:,:]=0\n",
    "        b[:,:2,:]=0\n",
    "        \n",
    "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        self.to_draw[t,:,:,:]=b\n",
    "\n",
    "\n",
    "    def act(self, action, train=True):\n",
    "        \"\"\"This function returns the new state, reward and decides if the\n",
    "        game ends.\"\"\"\n",
    "\n",
    "        self.get_frame(int(self.t))\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[:, -2:] = -1\n",
    "\n",
    "        self.position[self.x, self.y] = 1\n",
    "        if action == 0:\n",
    "            if self.x == self.grid_size-3:\n",
    "                self.x = self.x-1\n",
    "            else:\n",
    "                self.x = self.x + 1\n",
    "        elif action == 1:\n",
    "            if self.x == 2:\n",
    "                self.x = self.x+1\n",
    "            else:\n",
    "                self.x = self.x-1\n",
    "        elif action == 2:\n",
    "            if self.y == self.grid_size - 3:\n",
    "                self.y = self.y - 1\n",
    "            else:\n",
    "                self.y = self.y + 1\n",
    "        elif action == 3:\n",
    "            if self.y == 2:\n",
    "                self.y = self.y + 1\n",
    "            else:\n",
    "                self.y = self.y - 1\n",
    "        else:\n",
    "            RuntimeError('Error: action not recognized')\n",
    "\n",
    "        self.t = self.t + 1\n",
    "        reward = 0\n",
    "        if train:\n",
    "            reward = -self.malus_position[self.x, self.y]\n",
    "        self.malus_position[self.x, self.y] += 0.01\n",
    "\n",
    "        reward = reward + self.board[self.x, self.y]\n",
    "        reward_game = self.board[self.x, self.y]\n",
    "        self.board[self.x, self.y] = 0\n",
    "        game_over = self.t > self.max_time\n",
    "\n",
    "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
    "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
    "\n",
    "        return state, reward, reward_game, game_over\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
    "\n",
    "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "\n",
    "\n",
    "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
    "\n",
    "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
    "\n",
    "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "        malus[bonus>0]=0\n",
    "\n",
    "        self.board = bonus + malus\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.board[self.x,self.y] = 0\n",
    "        #self.malus_position[self.x, self.y] = 0.1\n",
    "        self.t = 0\n",
    "\n",
    "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
    "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "\n",
    "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
    "        return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1376
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "Ms9J_CNKEcby",
    "outputId": "8569759b-54dd-4ee5-8364-1e6097283ba1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(padding=\"same\", filters=32, kernel_size=(3, 3), input_shape=(5, 5, 3), activation=\"relu\")`\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(padding=\"same\", filters=64, kernel_size=(3, 3), input_shape=(5, 5, 3), activation=\"relu\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000/020 | Loss 0.0086 | Win/lose count 6.5/9.0 (-2.5)\n",
      "Epoch 001/020 | Loss 0.0060 | Win/lose count 5.5/4.0 (1.5)\n",
      "Epoch 002/020 | Loss 0.0068 | Win/lose count 4.0/2.0 (2.0)\n",
      "Epoch 003/020 | Loss 0.0205 | Win/lose count 6.0/5.0 (1.0)\n",
      "Epoch 004/020 | Loss 0.0208 | Win/lose count 8.5/6.0 (2.5)\n",
      "Epoch 005/020 | Loss 0.0584 | Win/lose count 6.5/4.0 (2.5)\n",
      "Epoch 006/020 | Loss 0.0105 | Win/lose count 3.0/6.0 (-3.0)\n",
      "Epoch 007/020 | Loss 0.0104 | Win/lose count 6.5/8.0 (-1.5)\n",
      "Epoch 008/020 | Loss 0.0107 | Win/lose count 6.0/0.5 (5.5)\n",
      "Epoch 009/020 | Loss 0.0173 | Win/lose count 10.0/4.0 (6.0)\n",
      "Epoch 010/020 | Loss 0.0103 | Win/lose count 12.0/3.0 (9.0)\n",
      "Epoch 011/020 | Loss 0.0154 | Win/lose count 10.0/4.5 (5.5)\n",
      "Epoch 012/020 | Loss 0.0135 | Win/lose count 14.5/9.0 (5.5)\n",
      "Epoch 013/020 | Loss 0.0277 | Win/lose count 14.5/4.0 (10.5)\n",
      "Epoch 014/020 | Loss 0.0182 | Win/lose count 2.5/1.0 (1.5)\n",
      "Epoch 015/020 | Loss 0.0286 | Win/lose count 7.5/2.0 (5.5)\n",
      "Epoch 016/020 | Loss 0.0192 | Win/lose count 11.0/2.0 (9.0)\n",
      "Epoch 017/020 | Loss 0.0196 | Win/lose count 11.5/2.0 (9.5)\n",
      "Epoch 018/020 | Loss 0.0166 | Win/lose count 6.5/1.0 (5.5)\n",
      "Epoch 019/020 | Loss 0.0212 | Win/lose count 20.0/1.5 (18.5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAGbRtZGF0AAACnwYF//+b3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDEzOCAtIEguMjY0L01QRUctNCBBVkMgY29kZWMgLSBDb3B5bGVmdCAyMDAzLTIwMTMgLSBodHRwOi8vd3d3LnZpZGVvbGFuLm9yZy94MjY0Lmh0bWwgLSBvcHRpb25zOiBjYWJhYz0xIHJlZj0zIGRlYmxvY2s9MTowOjAgYW5hbHlzZT0weDM6MHgxMTMgbWU9aGV4IHN1Ym1lPTcgcHN5PTEgcHN5X3JkPTEuMDA6MC4wMCBtaXhlZF9yZWY9MSBtZV9yYW5nZT0xNiBjaHJvbWFfbWU9MSB0cmVsbGlzPTEgOHg4ZGN0PTEgY3FtPTAgZGVhZHpvbmU9MjEsMTEgZmFzdF9wc2tpcD0xIGNocm9tYV9xcF9vZmZzZXQ9NCB0aHJlYWRzPTYgbG9va2FoZWFkX3RocmVhZHM9MSBzbGljZWRfdGhyZWFkcz0wIG5yPTAgZGVjaW1hdGU9MSBpbnRlcmxhY2VkPTAgYmx1cmF5X2NvbXBhdD0wIGNvbnN0cmFpbmVkX2ludHJhPTAgYmZyYW1lcz0zIGJfcHlyYW1pZD0yIGJfYWRhcHQ9MSBiX2JpYXM9MCBkaXJlY3Q9MSB3ZWlnaHRiPTEgb3Blbl9nb3A9MCB3ZWlnaHRwPTIga2V5aW50PTI1MCBrZXlpbnRfbWluPTI1IHNjZW5lY3V0PTQwIGludHJhX3JlZnJlc2g9MCByY19sb29rYWhlYWQ9NDAgcmM9Y3JmIG1idHJlZT0xIGNyZj0yMy4wIHFjb21wPTAuNjAgcXBtaW49MCBxcG1heD02OSBxcHN0ZXA9NCBpcF9yYXRpbz0xLjQwIGFxPTE6MS4wMACAAAADBWWIhAA3//72h/gU2VgTun/9P+C6zp85f52wATTYAUhuYKf7hNF8CmWxa/AoXQMX/3pjkS+vKU/wZ6KIqc+bdLyitMzO5ZhUFxCDfuBSP4TVOv6Os737htakSR6QGe3BQWXARwW+7NP9cxsBMlvgTWpn3/+vhNqtHBPt93YUBGGqTxb32ItiAZHeXORiydbxjnISo+hVGOJj+ra3zUU97YCwGyVZ96iewHqtFtangbMJFzVPeoQsPMWkDOscLHhXgkCPGglmV/bSdG41OPMqODC3VTOKbg7088f4b4L4N1W3Tofk2dlhBn4Q9S3obJZh5M9ozm8jhN5y/tj/URgRYX3a/E0G7ouPkxGOdXOz8/eJCQdPs0E/4OXa8EthRukXfA+PfaMu0A9yo9faAKimSRiCioHeWrB5I7M/a/aZb8TjBnLEYh+SGgY6y8eVhHbNbLNF1b4oav5hnfqcRd4xPWFiDWcv44qvgglUju7WYMjjQAeNRrpaWBv5fSR7CJiARTT9Ky3iydQoj2F3MkvBzQ0G6sf4AvBoT/l3SKU00PXMNOSBD7e4VTkaGCcd77VHKoeJlB5CSU1a8FYBhHGESLgxTNOZMQDxwB7v6pc6xuESdu7J+yFAP7jNZZdJiDNbieiTwgG5DQX0OCrnzYc2CPtUO+emJbdh0IpVcuLaQZGgqi+4Ur9pH/lBZ0+y+nKFJZYbJ03ULMd05QVJDqJvqHsd9q+AkUdZuEOzDnftfq8mWcsz0qGb7GoLJZmHNBa5AysSqiAgewTs4i4/xD87R1HRy9aPAGUSHRI0Ae9X2SUceFAo0skeXUTU/4+K5TlcmocNnXZbb3xuNmCQSw7Y8J5wmYBDLnzpZK7qOFdinLWsDmP3skefBEYP578VkiedhzP3FFGFjKjdjHveH7TmEx+kJ7iW3gEPDZX9xmdcrNHRVnxPQefZEP+drZ7T0SKJWVSZDKUNh3tAygLsohk4EstACDxoPf3qBUTIygVloba6hdxno6Sxyut2L1EBrl6GgBTY/DChAAAAHUGaJGxDP/6eEABJvgwcCmwNhOC5h40AbR7zPWcsAAAAJEGeQniF/wALXau4Qs3/CVWf/+IOgyWf/4afln/+IGO2jNlIsQAAABABnmF0Qr8ABnJK99fpQmygAAAAEAGeY2pCvwAPMzwLr+3EImEAAAAaQZplSahBaJlMCG///qeEABzzjP9VvmPxOOEAAAAZQZqGSeEKUmUwIb/+p4QALV6J/qt8x+JJwQAAACpBmqpJ4Q6JlMCG//6nhAAuvup98M9S5E/ApsDpS4FMtnHcChRUu/V1wEEAAAAmQZ7IRRE8L/8AHG0wf//H+T00NT+Mvh8hyFNG+x5Ht1bgQzCEDKAAAAAPAZ7ndEK/ACa+YMGzHErXAAAAEAGe6WpCvwAmsshh9ASDlPkAAAAaQZrrSahBaJlMCG///qeEAB8vYP8JwW6E20AAAAAaQZsPSeEKUmUwIb/+p4QAFR+NP4i2WGa63JQAAAAVQZ8tRTRML/8ADJBV0/cH3K5DwHXHAAAAEAGfTHRCvwAQ3cd5Wyh61oEAAAAQAZ9OakK/ABBdohNxn16mWQAAABpBm1BJqEFomUwIb//+p4QAFI91P1HGhIdSQAAAACZBm3RJ4QpSZTAhn/6eEAAzvCXU04wnLzLK57x8yxLBfMsmwcGp4AAAABBBn5JFNEwv/wAHxTqN7Bh1AAAADwGfsXRCvwAKzGMXAfmd4AAAABABn7NqQr8ACstyGH0BIO24AAAAGUGbtUmoQWiZTAhv//6nhAAI6PmPIxP8uB8AAAAZQZvWSeEKUmUwIb/+p4QACPfHT6jjQkPdwAAAAB9Bm/pJ4Q6JlMCG//6nhAAF191P2q81dm5lliZHV1eBAAAAEEGeGEURPC//AAN0q0bSfpUAAAAPAZ43dEK/AAS20YuA/PHgAAAADwGeOWpCvwAEtlbpRpDzJwAAABlBmjtJqEFomUwIb//+p4QAA6PsHr2Z8EaXAAAAKUGaX0nhClJlMCGf/p4QADJ6Ph3xCO8X//EIyVH/+zN9ePiXRNo7XNCBAAAAFkGefUU0TC//AAeZOj0P59Fi4NhZGCEAAAAQAZ6cdEK/AARX1EifFmKkcAAAABABnp5qQr8ACoWPHK/txEHAAAAAGUGagEmoQWiZTAhn//6eEABNThHP4c5vrnMAAAAYQZqhSeEKUmUwIZ/+nhAAdopxz+HOb63JAAAAGEGawknhDomUwIZ//p4QALnwY5/DnN9aqQAAABlBmuNJ4Q8mUwIb//6nhABJUAWbbZ9nzU3AAAAAGEGbBEnhDyZTAhv//qeEAEtHzHkYn+W3TQAAABlBmyVJ4Q8mUwId//6plgA6SZCTcOCj5pixAAAALEGbSUnhDyZTAh3//qmWAF499Xv83gK7hT5llXalPAph4LuBPVb4/4fe9kXzAAAAFkGfZ0URPC//AG59csZtf62kTVOTwLEAAAAQAZ+GdEK/AJb5qgdO1DVpgAAAABABn4hqQr8Alsshh9ASDi1IAAAAS0GbjUmoQWiZTAh3//6plgA9Xwo+5ey8e067GHDf/8QkeKmrvNDsEqv1xEeH///iBcs1dMtggt+FcX//8QgZU6u5I3BJK6hAZpeLgQAAACZBn6tFESwv/wBJaA66LH//j/J6aGp/GXw+Q5CmjfY+aUXBA9Ff8AAAABABn8p0Qr8AZIBTPK/JTZ/wAAAADwGfzGpCvwBBZXIq8AT/KwAAABtBm9FJqEFsmUwId//+qZYAEZ+l0Dh/qs5ebSUAAAAUQZ/vRRUsL/8AFQX6x+4PuVyIzZcAAAAQAZ4OdEK/ABxWwNbTKHqTQAAAABABnhBqQr8AHFqh3qn4/azoAAAALkGaFUmoQWyZTAhv//6nhAAh3x093m7G+NpH/EIC//wlRBZi//wkxH4v/9f9L7kAAAAVQZ4zRRUsL/8AFHY25C8+ixjbXQ/cAAAAEAGeUnRCvwAboAAMkt/rvcAAAAAQAZ5UakK/ABFZZDD6AkHSOQAAABxBmlZJqEFsmUwId//+qZYAByfiEDc7QdHU8tKAAAAAGkGaeknhClJlMCG//qeEAA56PMeh7sH8XIWBAAAAEEGemEU0TC//AAiugkCP6REAAAAPAZ63dEK/AAtcYQGSXR+AAAAAEAGeuWpCvwAL86p5LmfJ4oEAAAAqQZq+SahBaJlMCG///qeEADd+y+r4FNfUK/ApUtn4FM7AxH1zrbPto9XAAAAAFUGe3EURLC//ACC5+g4/nTOLNud8OwAAAA8Bnvt0Qr8AEt9J3Bsl5QcAAAAQAZ79akK/AC12PHK/tw/mwAAAABpBmv9JqEFsmUwIb//+p4QAVj0T/VcBj8RNwAAAABlBmwBJ4QpSZTAh3/6plgBCEWG6MQzn4hlRAAAAHEGbJEnhDomUwIb//qeEAM37B69mqazbePN4WqYAAAAVQZ9CRRE8L/8AvqbOTNtrq9BfQKLBAAAADwGfYXRCvwD+9KeB0ym5kwAAAA8Bn2NqQr8A/pW6UaQ8SmcAAAAqQZtoSahBaJlMCG///qeEASX46e62eBTYHSvwKZbOT4FCkzG8rZ2+rq3dAAAAFkGfhkURLC//ALXKx+uNJqhlH+dJ9QMAAAAQAZ+ldEK/APLGZEdizFGtSQAAABABn6dqQr8A8oLznVMxu0rAAAAAGUGbqUmoQWyZTAhv//6nhAEd+jmgrWZTWS8AAAAZQZvKSeEKUmUwId/+qZYAjPx50s6Op5FHwQAAACRBm+5J4Q6JlMCG//6nhAEN+jnx23ovzlfiEBf/4SpY8//48/wAAAAQQZ4MRRE8L/8Ao8+YkwRH5AAAAA8Bnit0Qr8A3KSiFMEWk4EAAAAQAZ4takK/ANyR251oYXiQQQAAABpBmi9JqEFomUwId//+qZYAV331ZVZm2YBRQQAAACFBmlNJ4QpSZTAhv/6nhACofGn47biyuBTZGCVyfmq6MCAAAAAVQZ5xRTRML/8AZIPqub9Ix9M5XOzKAAAADwGekHRCvwCGuyhSbZKpiwAAABABnpJqQr8AgrzRMiaVm3pAAAAAG0Gal0moQWiZTAhn//6eEAJd8Q/xpyEaA9q0bgAAABVBnrVFESwv/wBfoknnfWk/XIu0/IEAAAAQAZ7UdEK/AH74nik2yVTPgAAAABABntZqQr8AfxmDyYHr26CBAAAAGUGa2EmoQWyZTAhv//6nhACi4rSCET/LbTMAAAAYQZr5SeEKUmUwIb/+p4QAp2K0ghE/y20rAAAAGEGbGknhDomUwId//qmWAFb0srOK05C6YQAAACVBmz5J4Q8mUwId//6plgDmd+rmWWMKq8Cma4qeBRJ6uQ6tvI0PAAAAFUGfXEURPC//APKnUY3uVyIu5UFMWQAAAA8Bn3t0Qr8A3Mlm4NkvGWcAAAAQAZ99akK/AVGyITcZ9empuAAAABJBm2JJqEFomUwIb//+p4QAAScAAAAMQZ+ARREsL/8AALKBAAAAEAGfv3RCvwIL0A6FJE4ppWAAAAAQAZ+hakK/AU2yjvZ4+3TCgQAAABtBm6ZJqEFsmUwIZ//+nhAGy7pvrI652wTr1MAAAAAQQZ/ERRUsL/8A8qdHoodH5QAAAA8Bn+N0Qr8CC9AOhHy2VUEAAAAQAZ/lakK/AVFtyKvAE/lVgQAAABlBm+dJqEFsmUwIZ//+nhACoe6b6KlZr36TAAAAGEGaCEnhClJlMCGf/p4QAbHhK8t0My2/4AAAABhBmilJ4Q6JlMCG//6nhABseExR8GEGtlQAAAAYQZpKSeEPJlMCG//+p4QAafhMyuQW9NRfAAAAJkGabknhDyZTAhn//p4QAQb4h/7k3jviEd4v/+IRkqP/6X6Xv3TAAAAAFUGejEURPC//ACjs1n8iD2dO1lpi2AAAABABnqt0Qr8AN0AfFJtkqu6BAAAAEAGerWpCvwA0ztwm4z69O6UAAAAZQZqvSahBaJlMCGf//p4QAYeQxz+HOb6zlQAAABlBmtBJ4QpSZTAhv/6nhACaoAs22z7PmknAAAAAGUGa8UnhDomUwIb//qeEAOwcZ/qt8x+IN6AAAAAZQZsSSeEPJlMCHf/+qZYAwsWG6LdzH4Cj4QAAABZBmzZJ4Q8mUwId//6plgIB2Y/L2K+AAAAADkGfVEURPC//AVsRXjxgAAAAEAGfc3RCvwHSaVi8/gcjXkEAAAAQAZ91akK/AdHtDn+Zbv1vQAAAABNBm3pJqEFomUwId//+qZYAAJWBAAAADEGfmEURLC//AACygQAAABABn7d0Qr8B0mlYvP4HI15AAAAAEAGfuWpCvwErVI72ePt01oEAAAATQZu+SahBbJlMCHf//qmWAACVgAAAAAxBn9xFFSwv/wAAsoEAAAAQAZ/7dEK/AdJpWLz+ByNeQQAAABABn/1qQr8B0e0Of5lu/W9AAAAAHEGb4kmoQWyZTAh3//6plgDEePP5OrUC0UxBE7oAAAAQQZ4ARRUsL/8A3IjjO5PyoQAAABABnj90Qr8BNtx3lbKHo5GAAAAADwGeIWpCvwDNgsbA5TaggQAAABlBmiZJqEFsmUwId//+qZYAwt+7I+jH6MlbAAAAFUGeREUVLC//AWT1x7e3BvD5L5ncqQAAABABnmN0Qr8B30Q9gdMbuRWBAAAAEAGeZWpCvwHesv1R8x+LY0EAAAAZQZpqSahBbJlMCG///qeEAYLx0+1h9nXDuwAAABJBnohFFSwv/wFliWrUff1G7lQAAAAPAZ6ndEK/Ad9EMyGgZnG9AAAADwGeqWpCvwHethVXgB/yKwAAABpBmqtJqEFsmUwId//+qZYAfMdPymjH60k/wAAAACpBms9J4QpSZTAh3/6plgLlxoOZZWqarwKUSBeBTNcrpbdv/SqQY/zzGfAAAAAUQZ7tRTRML/8Bh++V4/4MpNWtx2EAAAAPAZ8MdEK/ANfIfjeoI1mfAAAAEAGfDmpCvwILY66B+P4aZ8EAAAAbQZsTSahBaJlMCHf//qmWAtROdcU+UMOmmJ0wAAAAEkGfMUURLC//AYeQSuD/l5bt3AAAABABn1B0Qr8CCpyrqzvaTTPhAAAAEAGfUmpCvwFIsiE3GfXpqggAAAATQZtXSahBbJlMCHf//qmWAACVgAAAAAxBn3VFFSwv/wAAsoEAAAAPAZ+UdEK/AUT/5LUB+WfVAAAADwGflmpCvwFE/+SlAfln1QAAACRBm5tJqEFsmUwId//+qZYA3GeZD4fi6yyyH//4Sqhm//2Ty4EAAAAVQZ+5RRUsL/8A7P8PVP+ixbgAEe7oAAAADwGf2HRCvwFITlCk2yVRSQAAABABn9pqQr8AzZMk030kHFNwAAAAE0Gb30moQWyZTAh3//6plgAAlYEAAAAMQZ/9RRUsL/8AALKBAAAADwGeHHRCvwCFUPJagPy1NgAAAA8Bnh5qQr8AhVDyUoD8tTYAAAASQZoDSahBbJlMCG///qeEAAEnAAAADEGeIUUVLC//AACygAAAABABnkB0Qr8A0tlXdX47v30hAAAAEAGeQmpCvwDSpWxersOR6EAAAAAkQZpHSahBbJlMCGf//p4QAo/MrqPTRjmCmkIv/+IRkqP/4xUxAAAAEEGeZUUVLC//AGSVc9FDqdkAAAAPAZ6EdEK/AIbaMXAflqbBAAAADwGehmpCvwCGyuRV4An9QwAAABlBmohJqEFsmUwIZ//+nhABDum3SyGPzISoAAAAGEGaqUnhClJlMCG//qeEAC2cyuKZFCfBMwAAABhBmspJ4Q6JlMCG//6nhAAdHhMyuQW9Np8AAAAYQZrrSeEPJlMCHf/+qZYACY9WwmWZ8+VHAAAAHEGbD0nhDyZTAh3//qmWAAlPVsiMcxBTijHzjBwAAAAUQZ8tRRE8L/8ACxMsVt8x7ktZdkEAAAAQAZ9MdEK/AA7XFFwH5QAR4QAAAA8Bn05qQr8ACfWEeTA9fF8AAAAdQZtTSahBaJlMCHf//qmWAAYzi9GFfCYwLRZ45aIAAAAQQZ9xRREsL/8AB0E6PRRCWAAAAA8Bn5B0Qr8ADzWKxhCrmsEAAAAQAZ+SakK/AAnzbkVeAKCjgAAAABxBm5dJqEFsmUwId//+qZYAApfvq++MKgWimIkeAAAAEEGftUUVLC//AAMQI4zuh6EAAAAQAZ/UdEK/AAQ3cd5Wyh8ygAAAAA8Bn9ZqQr8AAtajRNSVjoEAAAASQZvbSahBbJlMCG///qeEAAEnAAAAEUGf+UUVLC//AAMQ5ErvIh6AAAAAEAGeGHRCvwAENZ/EzvIXmUEAAAAQAZ4aakK/AAQWWQw+gJB/2AAAAB5Bmh9JqEFsmUwIb//+p4QAA7nrDcyyxMjvXZ5tjmcAAAAjQZ49RRUsL/8AAjuglYo///H+T00NT+Mvh8hyFNG+x/sLOncAAAAPAZ5cdEK/AALplgwbMcYfAAAAEAGeXmpCvwADEOqeS5nzBYAAAAAbQZpASahBbJlMCG///qeEAAO57Kxm9BWsynZZAAAAGUGaZEnhClJlMCGf/p4QAA7Rz4/73oL7s9YAAAAQQZ6CRTRML/8AAkugkCQNkQAAAA8BnqF0Qr8AAvySiFMFBYAAAAAQAZ6jakK/AAMk6p5LmfMAgQAAABhBmqVJqEFomUwIZ//+nhAADyeuNdVwVf0AAAAaQZrJS+EIQpSRGCCgH8gH9h4AhX/+OEAAEXEAAAAjQZ7nRTRML/8CAdzqS9szCrmA6Bq1qFwJQBlok8LfMpM0nDEAAAAQAZ8GdEK/AAT7oB0LGJx3kAAAACQBnwhqQr8Cr2PtQcTdqsNJJuWqhgcstbvNKiCaLC4i0lJgIb4AAAvpbW9vdgAAAGxtdmhkAAAAAAAAAAAAAAAAAAAD6AAAH5AAAQAAAQAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgAACxN0cmFrAAAAXHRraGQAAAADAAAAAAAAAAAAAAABAAAAAAAAH5AAAAAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAABAAAAAARAAAAEQAAAAAAAkZWR0cwAAABxlbHN0AAAAAAAAAAEAAB+QAAAEAAABAAAAAAqLbWRpYQAAACBtZGhkAAAAAAAAAAAAAAAAAAAyAAABlABVxAAAAAAALWhkbHIAAAAAAAAAAHZpZGUAAAAAAAAAAAAAAABWaWRlb0hhbmRsZXIAAAAKNm1pbmYAAAAUdm1oZAAAAAEAAAAAAAAAAAAAACRkaW5mAAAAHGRyZWYAAAAAAAAAAQAAAAx1cmwgAAAAAQAACfZzdGJsAAAAlnN0c2QAAAAAAAAAAQAAAIZhdmMxAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAARABEABIAAAASAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGP//AAAAMGF2Y0MB9AAN/+EAF2f0AA2RmygiEdCAAAADAIAAABkHihTLAQAGaOvjxEhEAAAAGHN0dHMAAAAAAAAAAQAAAMoAAAIAAAAAFHN0c3MAAAAAAAAAAQAAAAEAAAXAY3R0cwAAAAAAAAC2AAAAAQAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAIAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAIAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAABgAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAIAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAIAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAADAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAQAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAAEAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAAEAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAABxzdHNjAAAAAAAAAAEAAAABAAAAygAAAAEAAAM8c3RzegAAAAAAAAAAAAAAygAABawAAAAhAAAAKAAAABQAAAAUAAAAHgAAAB0AAAAuAAAAKgAAABMAAAAUAAAAHgAAAB4AAAAZAAAAFAAAABQAAAAeAAAAKgAAABQAAAATAAAAFAAAAB0AAAAdAAAAIwAAABQAAAATAAAAEwAAAB0AAAAtAAAAGgAAABQAAAAUAAAAHQAAABwAAAAcAAAAHQAAABwAAAAdAAAAMAAAABoAAAAUAAAAFAAAAE8AAAAqAAAAFAAAABMAAAAfAAAAGAAAABQAAAAUAAAAMgAAABkAAAAUAAAAFAAAACAAAAAeAAAAFAAAABMAAAAUAAAALgAAABkAAAATAAAAFAAAAB4AAAAdAAAAIAAAABkAAAATAAAAEwAAAC4AAAAaAAAAFAAAABQAAAAdAAAAHQAAACgAAAAUAAAAEwAAABQAAAAeAAAAJQAAABkAAAATAAAAFAAAAB8AAAAZAAAAFAAAABQAAAAdAAAAHAAAABwAAAApAAAAGQAAABMAAAAUAAAAFgAAABAAAAAUAAAAFAAAAB8AAAAUAAAAEwAAABQAAAAdAAAAHAAAABwAAAAcAAAAKgAAABkAAAAUAAAAFAAAAB0AAAAdAAAAHQAAAB0AAAAaAAAAEgAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABcAAAAQAAAAFAAAABQAAAAgAAAAFAAAABQAAAATAAAAHQAAABkAAAAUAAAAFAAAAB0AAAAWAAAAEwAAABMAAAAeAAAALgAAABgAAAATAAAAFAAAAB8AAAAWAAAAFAAAABQAAAAXAAAAEAAAABMAAAATAAAAKAAAABkAAAATAAAAFAAAABcAAAAQAAAAEwAAABMAAAAWAAAAEAAAABQAAAAUAAAAKAAAABQAAAATAAAAEwAAAB0AAAAcAAAAHAAAABwAAAAgAAAAGAAAABQAAAATAAAAIQAAABQAAAATAAAAFAAAACAAAAAUAAAAFAAAABMAAAAWAAAAFQAAABQAAAAUAAAAIgAAACcAAAATAAAAFAAAAB8AAAAdAAAAFAAAABMAAAAUAAAAHAAAAB4AAAAnAAAAFAAAACgAAAAUc3RjbwAAAAAAAAABAAAAMAAAAGJ1ZHRhAAAAWm1ldGEAAAAAAAAAIWhkbHIAAAAAAAAAAG1kaXJhcHBsAAAAAAAAAAAAAAAALWlsc3QAAAAlqXRvbwAAAB1kYXRhAAAAAQAAAABMYXZmNTcuODMuMTAw\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "epochs_train = 20\n",
    "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.3)\n",
    "agent = DQN_CNN(size, lr=.1, epsilon = 0.6, memory_size=2000, batch_size = 32,n_state=3)\n",
    "train_explore(agent, env, epochs_train, prefix='cnn_train_explore')\n",
    "HTML(display_videos('cnn_train_explore20.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_explore(agent,env,epochs,prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "        \n",
    "    for e in range(epochs):\n",
    "    # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "    # This assumes that the games will end\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "\n",
    "        while not game_over:\n",
    "        # The agent performs an action\n",
    "            action = agent.act(state)\n",
    "\n",
    "        # Apply an action to the environment, get the next state, the reward\n",
    "        # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward,reward_game, game_over = env.act(action,train=False)\n",
    "\n",
    "        # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward_game\n",
    "            if reward < 0:\n",
    "                lose = lose -reward_game\n",
    "\n",
    "        # Apply the reinforcement strategy\n",
    "            #loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "       \n",
    "        # Save as a mp4\n",
    "        env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score = score + win-lose\n",
    "\n",
    "        print(\"Win/lose count {}/{}. Average score ({})\"\n",
    "              .format(win, lose, score/(1+e)))\n",
    "    print('Final score: '+str(score/epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "gpspLf0zEcb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win/lose count 10.5/3.0. Average score (7.5)\n",
      "Win/lose count 2.5/1.0. Average score (4.5)\n",
      "Win/lose count 5.5/0. Average score (4.833333333333333)\n",
      "Win/lose count 2.5/0. Average score (4.25)\n",
      "Win/lose count 2.5/2.0. Average score (3.5)\n",
      "Win/lose count 10.5/1.0. Average score (4.5)\n",
      "Win/lose count 7.5/0. Average score (4.928571428571429)\n",
      "Win/lose count 8.5/1.0. Average score (5.25)\n",
      "Win/lose count 3.5/2.0. Average score (4.833333333333333)\n",
      "Win/lose count 4.0/2.0. Average score (4.55)\n",
      "Win/lose count 9.5/0. Average score (5.0)\n",
      "Final score: 5.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation\n",
    "epochs_test = 11\n",
    "test_explore(agent,env,epochs_test,prefix='cnn_test_explore')\n",
    "HTML(display_videos('cnn_test_explore10.mp4'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oIw5IUMNEcb4"
   },
   "source": [
    "***\n",
    "***\n",
    "__BONUS question__ Use the expert DQN from the previous question to generate some winning games. Train a model that mimicks its behavior. Compare the performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OKIr9TKYEcb4"
   },
   "source": [
    "By trainning a model based on the historical data of states and actions of the winning games (x = states, y = actions), we found that it can produce a comparable agent to the previous DQN_CNN model, with far less time.\n",
    "\n",
    "The preselected data (data of winning games) is very helpful for the training of the agent. The agent will find the 'proper' action far quickly by mimicking the behavor of a winned agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# geberate winning games\n",
    "def gen_wingame(agent,env,epochs,prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "    win_states = []\n",
    "    \n",
    "    win_actions = []\n",
    "        \n",
    "    for e in range(epochs):\n",
    "    # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "    # This assumes that the games will end\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "\n",
    "        while not game_over:\n",
    "        # The agent performs an action\n",
    "            action = agent.act(state)\n",
    "            agent.set_epsilon(0.95*agent.epsilon)\n",
    "\n",
    "        # Apply an action to the environment, get the next state, the reward\n",
    "        # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, reward_game, game_over = env.act(action, train=True)\n",
    "\n",
    "        # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward_game\n",
    "                win_states.append(prev_state)\n",
    "                win_actions.append(action)\n",
    "            if reward < 0:\n",
    "                lose = lose - reward_game\n",
    "\n",
    "        # Apply the reinforcement strategy\n",
    "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "       \n",
    "        # Save as a mp4\n",
    "        if e % 10 == 0:\n",
    "            #env.draw(prefix+str(e))\n",
    "            agent.set_epsilon(np.fmax(0.05,agent.epsilon/2.))\n",
    "\n",
    "        # Update stats\n",
    "        score = score + win-lose\n",
    "    \n",
    "\n",
    "        #print(\"Win/lose count {}/{}. Average score ({})\"\n",
    "        #      .format(win, lose, score/(1+e)))\n",
    "    #print('Final score: '+str(score/epochs))\n",
    "    return  win_states, win_actions\n",
    "\n",
    "def gen_wingames(epochs,n_games,prefix=''):\n",
    "    \n",
    "    win_states = [] \n",
    "    win_actions = []\n",
    "    for i in range(n_games):\n",
    "        demon_env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.3)\n",
    "        demon_agent = DQN_CNN(size, lr=.1, epsilon = 0.5, memory_size=2000, batch_size = 32,n_state=3)\n",
    "        win_states_i, win_actions_i = gen_wingame(demon_agent,demon_env,epochs,prefix=prefix)\n",
    "        win_states.extend(win_states_i)\n",
    "        win_actions.extend(win_actions_i)\n",
    "        del demon_agent, demon_env\n",
    "        print('------------{}th game-----------'.format(i))\n",
    "    return win_states, win_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(padding=\"same\", filters=32, kernel_size=(3, 3), input_shape=(5, 5, 3), activation=\"relu\")`\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(padding=\"same\", filters=64, kernel_size=(3, 3), input_shape=(5, 5, 3), activation=\"relu\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------0th game-----------\n",
      "------------1th game-----------\n",
      "------------2th game-----------\n",
      "------------3th game-----------\n",
      "------------4th game-----------\n",
      "------------5th game-----------\n"
     ]
    }
   ],
   "source": [
    "game_epochs = 25\n",
    "n_games = 6\n",
    "win_states_tp, win_actions_tp = gen_wingames(game_epochs,n_games,prefix='gen_wingames')\n",
    "win_states.extend(win_states_tp)\n",
    "win_actions.extend(win_actions_tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gv4Hllb6Ecb5"
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(padding=\"same\", filters=32, kernel_size=(3, 3), input_shape=(5, 5, 3), activation=\"relu\")`\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(padding=\"same\", filters=64, kernel_size=(3, 3), input_shape=(5, 5, 3), activation=\"relu\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_61 (Conv2D)           (None, 5, 5, 32)          896       \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 5, 5, 64)          18496     \n",
      "_________________________________________________________________\n",
      "flatten_33 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 224,836\n",
      "Trainable params: 224,836\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 3680 samples, validate on 1578 samples\n",
      "Epoch 1/100\n",
      "3680/3680 [==============================] - 2s 426us/step - loss: 0.7922 - acc: 0.6842 - val_loss: 0.3042 - val_acc: 0.8523\n",
      "Epoch 2/100\n",
      "3680/3680 [==============================] - 1s 175us/step - loss: 0.3069 - acc: 0.8633 - val_loss: 0.2780 - val_acc: 0.8707\n",
      "Epoch 3/100\n",
      "3680/3680 [==============================] - 1s 187us/step - loss: 0.2608 - acc: 0.8812 - val_loss: 0.2569 - val_acc: 0.8910\n",
      "Epoch 4/100\n",
      "3680/3680 [==============================] - 1s 203us/step - loss: 0.2337 - acc: 0.8894 - val_loss: 0.2577 - val_acc: 0.8771\n",
      "Epoch 5/100\n",
      "3680/3680 [==============================] - 1s 198us/step - loss: 0.2207 - acc: 0.8981 - val_loss: 0.2771 - val_acc: 0.8815\n",
      "Epoch 6/100\n",
      "3680/3680 [==============================] - 1s 183us/step - loss: 0.1973 - acc: 0.9071 - val_loss: 0.2677 - val_acc: 0.8707\n",
      "Epoch 7/100\n",
      "3680/3680 [==============================] - 1s 186us/step - loss: 0.1918 - acc: 0.9120 - val_loss: 0.2715 - val_acc: 0.8809\n",
      "Epoch 8/100\n",
      "3680/3680 [==============================] - 1s 182us/step - loss: 0.1785 - acc: 0.9168 - val_loss: 0.2695 - val_acc: 0.8739\n",
      "Epoch 9/100\n",
      "3680/3680 [==============================] - 1s 197us/step - loss: 0.1664 - acc: 0.9231 - val_loss: 0.2534 - val_acc: 0.8847\n",
      "Epoch 10/100\n",
      "3680/3680 [==============================] - 1s 177us/step - loss: 0.1554 - acc: 0.9304 - val_loss: 0.3174 - val_acc: 0.8644\n",
      "Epoch 11/100\n",
      "3680/3680 [==============================] - 1s 205us/step - loss: 0.1461 - acc: 0.9348 - val_loss: 0.2834 - val_acc: 0.8745\n",
      "Epoch 12/100\n",
      "3680/3680 [==============================] - 1s 188us/step - loss: 0.1324 - acc: 0.9416 - val_loss: 0.2886 - val_acc: 0.8809\n",
      "Epoch 13/100\n",
      "3680/3680 [==============================] - 1s 192us/step - loss: 0.1211 - acc: 0.9481 - val_loss: 0.3015 - val_acc: 0.8707\n",
      "Epoch 14/100\n",
      "3680/3680 [==============================] - 1s 203us/step - loss: 0.1092 - acc: 0.9541 - val_loss: 0.2959 - val_acc: 0.8739\n",
      "Epoch 15/100\n",
      "3680/3680 [==============================] - 1s 188us/step - loss: 0.1017 - acc: 0.9579 - val_loss: 0.3239 - val_acc: 0.8745\n",
      "Epoch 16/100\n",
      "3680/3680 [==============================] - 1s 174us/step - loss: 0.0938 - acc: 0.9655 - val_loss: 0.3468 - val_acc: 0.8688\n",
      "Epoch 17/100\n",
      "3680/3680 [==============================] - 1s 175us/step - loss: 0.0798 - acc: 0.9728 - val_loss: 0.4045 - val_acc: 0.8657\n",
      "Epoch 18/100\n",
      "3680/3680 [==============================] - 1s 177us/step - loss: 0.0678 - acc: 0.9753 - val_loss: 0.3519 - val_acc: 0.8676\n",
      "Epoch 19/100\n",
      "3680/3680 [==============================] - 1s 194us/step - loss: 0.0635 - acc: 0.9802 - val_loss: 0.3809 - val_acc: 0.8707\n",
      "Epoch 20/100\n",
      "3680/3680 [==============================] - 1s 197us/step - loss: 0.0565 - acc: 0.9818 - val_loss: 0.3831 - val_acc: 0.8853\n",
      "Epoch 21/100\n",
      "3680/3680 [==============================] - 1s 184us/step - loss: 0.0467 - acc: 0.9851 - val_loss: 0.4161 - val_acc: 0.8752\n",
      "Epoch 22/100\n",
      "3680/3680 [==============================] - 1s 177us/step - loss: 0.0417 - acc: 0.9886 - val_loss: 0.4285 - val_acc: 0.8695\n",
      "Epoch 23/100\n",
      "3680/3680 [==============================] - 1s 180us/step - loss: 0.0328 - acc: 0.9938 - val_loss: 0.4213 - val_acc: 0.8745\n",
      "Epoch 24/100\n",
      "3680/3680 [==============================] - 1s 178us/step - loss: 0.0301 - acc: 0.9932 - val_loss: 0.4323 - val_acc: 0.8752\n",
      "Epoch 25/100\n",
      "3680/3680 [==============================] - 1s 179us/step - loss: 0.0224 - acc: 0.9967 - val_loss: 0.4565 - val_acc: 0.8733\n",
      "Epoch 26/100\n",
      "3680/3680 [==============================] - 1s 178us/step - loss: 0.0193 - acc: 0.9986 - val_loss: 0.4679 - val_acc: 0.8745\n",
      "Epoch 27/100\n",
      "3680/3680 [==============================] - 1s 200us/step - loss: 0.0136 - acc: 0.9997 - val_loss: 0.4650 - val_acc: 0.8783\n",
      "Epoch 28/100\n",
      "3680/3680 [==============================] - 1s 188us/step - loss: 0.0120 - acc: 0.9997 - val_loss: 0.5018 - val_acc: 0.8739\n",
      "Epoch 29/100\n",
      "3680/3680 [==============================] - 1s 177us/step - loss: 0.0106 - acc: 0.9995 - val_loss: 0.4920 - val_acc: 0.8720\n",
      "Epoch 30/100\n",
      "3680/3680 [==============================] - 1s 223us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.5005 - val_acc: 0.8720\n",
      "Epoch 31/100\n",
      "3680/3680 [==============================] - 1s 201us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.5252 - val_acc: 0.8739\n",
      "Epoch 32/100\n",
      "3680/3680 [==============================] - 1s 188us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.5351 - val_acc: 0.8733\n",
      "Epoch 33/100\n",
      "3680/3680 [==============================] - 1s 199us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.5216 - val_acc: 0.8745\n",
      "Epoch 34/100\n",
      "3680/3680 [==============================] - 1s 194us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.5440 - val_acc: 0.8764\n",
      "Epoch 35/100\n",
      "3680/3680 [==============================] - 1s 175us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.5372 - val_acc: 0.8771\n",
      "Epoch 36/100\n",
      "3680/3680 [==============================] - 1s 169us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.5700 - val_acc: 0.8726\n",
      "Epoch 37/100\n",
      "3680/3680 [==============================] - 1s 213us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.5757 - val_acc: 0.8733\n",
      "Epoch 38/100\n",
      "3680/3680 [==============================] - 1s 239us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.5735 - val_acc: 0.8739\n",
      "Epoch 39/100\n",
      "3680/3680 [==============================] - 1s 196us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.5738 - val_acc: 0.8739\n",
      "Epoch 40/100\n",
      "3680/3680 [==============================] - 1s 211us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.5887 - val_acc: 0.8733\n",
      "Epoch 41/100\n",
      "3680/3680 [==============================] - 1s 191us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.5965 - val_acc: 0.8726\n",
      "Epoch 42/100\n",
      "3680/3680 [==============================] - 1s 197us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.6047 - val_acc: 0.8745\n",
      "Epoch 43/100\n",
      "3680/3680 [==============================] - 1s 195us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.6034 - val_acc: 0.8739\n",
      "Epoch 44/100\n",
      "3680/3680 [==============================] - 1s 188us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.5981 - val_acc: 0.8745\n",
      "Epoch 45/100\n",
      "3680/3680 [==============================] - 1s 178us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.6121 - val_acc: 0.8720\n",
      "Epoch 46/100\n",
      "3680/3680 [==============================] - 1s 184us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.6096 - val_acc: 0.8745\n",
      "Epoch 47/100\n",
      "3680/3680 [==============================] - 1s 209us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.6177 - val_acc: 0.8726\n",
      "Epoch 48/100\n",
      "3680/3680 [==============================] - 1s 218us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.6222 - val_acc: 0.8771\n",
      "Epoch 49/100\n",
      "3680/3680 [==============================] - 1s 191us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.6279 - val_acc: 0.8758\n",
      "Epoch 50/100\n",
      "3680/3680 [==============================] - 1s 179us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6320 - val_acc: 0.8758\n",
      "Epoch 51/100\n",
      "3680/3680 [==============================] - 1s 180us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6325 - val_acc: 0.8752\n",
      "Epoch 52/100\n",
      "3680/3680 [==============================] - 1s 178us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6323 - val_acc: 0.8745\n",
      "Epoch 53/100\n",
      "3680/3680 [==============================] - 1s 183us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6435 - val_acc: 0.8758\n",
      "Epoch 54/100\n",
      "3680/3680 [==============================] - 1s 194us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6417 - val_acc: 0.8745\n",
      "Epoch 55/100\n",
      "3680/3680 [==============================] - 1s 198us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6420 - val_acc: 0.8758\n",
      "Epoch 56/100\n",
      "3680/3680 [==============================] - 1s 208us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6510 - val_acc: 0.8752\n",
      "Epoch 57/100\n",
      "3680/3680 [==============================] - 1s 205us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6519 - val_acc: 0.8733\n",
      "Epoch 58/100\n",
      "3680/3680 [==============================] - 1s 193us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6536 - val_acc: 0.8752\n",
      "Epoch 59/100\n",
      "3680/3680 [==============================] - 1s 190us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6601 - val_acc: 0.8739\n",
      "Epoch 60/100\n",
      "3680/3680 [==============================] - 1s 179us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.6643 - val_acc: 0.8752\n",
      "Epoch 61/100\n",
      "3680/3680 [==============================] - 1s 180us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.6649 - val_acc: 0.8752\n",
      "Epoch 62/100\n",
      "3680/3680 [==============================] - 1s 208us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.6717 - val_acc: 0.8739\n",
      "Epoch 63/100\n",
      "3680/3680 [==============================] - 1s 213us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.6649 - val_acc: 0.8758\n",
      "Epoch 64/100\n",
      "3680/3680 [==============================] - 1s 188us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.6697 - val_acc: 0.8745\n",
      "Epoch 65/100\n",
      "3680/3680 [==============================] - 1s 197us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.6686 - val_acc: 0.8745\n",
      "Epoch 66/100\n",
      "3680/3680 [==============================] - 1s 185us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.6688 - val_acc: 0.8758\n",
      "Epoch 67/100\n",
      "3680/3680 [==============================] - 1s 181us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.6802 - val_acc: 0.8739\n",
      "Epoch 68/100\n",
      "3680/3680 [==============================] - 1s 178us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.6828 - val_acc: 0.8752\n",
      "Epoch 69/100\n",
      "3680/3680 [==============================] - 1s 229us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.6822 - val_acc: 0.8745\n",
      "Epoch 70/100\n",
      "3680/3680 [==============================] - 1s 194us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.6845 - val_acc: 0.8739\n",
      "Epoch 71/100\n",
      "3680/3680 [==============================] - 1s 179us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.6915 - val_acc: 0.8733\n",
      "Epoch 72/100\n",
      "3680/3680 [==============================] - 1s 215us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.6878 - val_acc: 0.8752\n",
      "Epoch 73/100\n",
      "3680/3680 [==============================] - 1s 242us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.6893 - val_acc: 0.8758\n",
      "Epoch 74/100\n",
      "3680/3680 [==============================] - 1s 247us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.6938 - val_acc: 0.8739\n",
      "Epoch 75/100\n",
      "3680/3680 [==============================] - 1s 238us/step - loss: 9.8865e-04 - acc: 1.0000 - val_loss: 0.6907 - val_acc: 0.8752\n",
      "Epoch 76/100\n",
      "3680/3680 [==============================] - 1s 210us/step - loss: 9.7136e-04 - acc: 1.0000 - val_loss: 0.6984 - val_acc: 0.8739\n",
      "Epoch 77/100\n",
      "3680/3680 [==============================] - 1s 214us/step - loss: 9.5069e-04 - acc: 1.0000 - val_loss: 0.6969 - val_acc: 0.8752\n",
      "Epoch 78/100\n",
      "3680/3680 [==============================] - 1s 163us/step - loss: 9.2961e-04 - acc: 1.0000 - val_loss: 0.7018 - val_acc: 0.8739\n",
      "Epoch 79/100\n",
      "3680/3680 [==============================] - 1s 161us/step - loss: 9.1864e-04 - acc: 1.0000 - val_loss: 0.7023 - val_acc: 0.8739\n",
      "Epoch 80/100\n",
      "3680/3680 [==============================] - 1s 164us/step - loss: 9.0167e-04 - acc: 1.0000 - val_loss: 0.7055 - val_acc: 0.8733\n",
      "Epoch 81/100\n",
      "3680/3680 [==============================] - 1s 160us/step - loss: 8.8618e-04 - acc: 1.0000 - val_loss: 0.7087 - val_acc: 0.8726\n",
      "Epoch 82/100\n",
      "3680/3680 [==============================] - 1s 161us/step - loss: 8.7204e-04 - acc: 1.0000 - val_loss: 0.7065 - val_acc: 0.8752\n",
      "Epoch 83/100\n",
      "3680/3680 [==============================] - 1s 195us/step - loss: 8.5436e-04 - acc: 1.0000 - val_loss: 0.7103 - val_acc: 0.8733\n",
      "Epoch 84/100\n",
      "3680/3680 [==============================] - 1s 223us/step - loss: 8.3845e-04 - acc: 1.0000 - val_loss: 0.7114 - val_acc: 0.8752\n",
      "Epoch 85/100\n",
      "3680/3680 [==============================] - 1s 282us/step - loss: 8.2805e-04 - acc: 1.0000 - val_loss: 0.7138 - val_acc: 0.8739\n",
      "Epoch 86/100\n",
      "3680/3680 [==============================] - 1s 224us/step - loss: 8.0842e-04 - acc: 1.0000 - val_loss: 0.7092 - val_acc: 0.8752\n",
      "Epoch 87/100\n",
      "3680/3680 [==============================] - 1s 211us/step - loss: 7.9985e-04 - acc: 1.0000 - val_loss: 0.7115 - val_acc: 0.8752\n",
      "Epoch 88/100\n",
      "3680/3680 [==============================] - 1s 207us/step - loss: 7.8742e-04 - acc: 1.0000 - val_loss: 0.7132 - val_acc: 0.8752\n",
      "Epoch 89/100\n",
      "3680/3680 [==============================] - 1s 249us/step - loss: 7.7740e-04 - acc: 1.0000 - val_loss: 0.7147 - val_acc: 0.8758\n",
      "Epoch 90/100\n",
      "3680/3680 [==============================] - 1s 259us/step - loss: 7.6499e-04 - acc: 1.0000 - val_loss: 0.7196 - val_acc: 0.8745\n",
      "Epoch 91/100\n",
      "3680/3680 [==============================] - 1s 211us/step - loss: 7.5383e-04 - acc: 1.0000 - val_loss: 0.7198 - val_acc: 0.8752\n",
      "Epoch 92/100\n",
      "3680/3680 [==============================] - 1s 193us/step - loss: 7.4226e-04 - acc: 1.0000 - val_loss: 0.7229 - val_acc: 0.8745\n",
      "Epoch 93/100\n",
      "3680/3680 [==============================] - 1s 184us/step - loss: 7.3093e-04 - acc: 1.0000 - val_loss: 0.7206 - val_acc: 0.8745\n",
      "Epoch 94/100\n",
      "3680/3680 [==============================] - 1s 196us/step - loss: 7.2069e-04 - acc: 1.0000 - val_loss: 0.7233 - val_acc: 0.8752\n",
      "Epoch 95/100\n",
      "3680/3680 [==============================] - 1s 210us/step - loss: 7.1125e-04 - acc: 1.0000 - val_loss: 0.7270 - val_acc: 0.8733\n",
      "Epoch 96/100\n",
      "3680/3680 [==============================] - 1s 207us/step - loss: 7.0212e-04 - acc: 1.0000 - val_loss: 0.7281 - val_acc: 0.8739\n",
      "Epoch 97/100\n",
      "3680/3680 [==============================] - 1s 184us/step - loss: 6.9188e-04 - acc: 1.0000 - val_loss: 0.7293 - val_acc: 0.8745\n",
      "Epoch 98/100\n",
      "3680/3680 [==============================] - 1s 179us/step - loss: 6.7862e-04 - acc: 1.0000 - val_loss: 0.7271 - val_acc: 0.8752\n",
      "Epoch 99/100\n",
      "3680/3680 [==============================] - 1s 180us/step - loss: 6.7458e-04 - acc: 1.0000 - val_loss: 0.7314 - val_acc: 0.8745\n",
      "Epoch 100/100\n",
      "3680/3680 [==============================] - 1s 195us/step - loss: 6.6390e-04 - acc: 1.0000 - val_loss: 0.7286 - val_acc: 0.8745\n"
     ]
    }
   ],
   "source": [
    "#create a new agent learning from the learning games\n",
    "class DQN_demonstrate(DQN):\n",
    "    def __init__(self, *args,lr=0.1,**kwargs):\n",
    "        super(DQN_demonstrate, self).__init__(*args,**kwargs)\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Convolution2D(filters=32,nb_row=3,nb_col=3, activation='relu',padding='same',input_shape=(5,5,self.n_state)))\n",
    "        model.add(Convolution2D(filters=64,nb_row=3,nb_col=3, activation='relu',padding='same',input_shape=(5,5,self.n_state)))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dense(4, activation='softmax'))\n",
    "        \n",
    "        print(model.summary())\n",
    "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "        self.model = model\n",
    "        \n",
    "agent_demon = DQN_demonstrate(size, lr=.1, epsilon = 0.3, memory_size=2000, batch_size = 32,n_state=3)\n",
    "save_model_path = '{}_weights.h5'.format('gen_wingames')\n",
    "history = agent_demon.model.fit(np.array(win_states),\n",
    "                to_categorical(win_actions, num_classes=4),\n",
    "                epochs=100,\n",
    "                validation_split=0.3,\n",
    "                callbacks=[ModelCheckpoint(save_model_path, monitor='val_acc', save_best_only=True)\n",
    "                ]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win/lose count 10.5/3.0. Average score (7.5)\n",
      "Win/lose count 16.0/12.0. Average score (5.75)\n",
      "Win/lose count 18.0/9.0. Average score (6.833333333333333)\n",
      "Win/lose count 17.5/9.0. Average score (7.25)\n",
      "Win/lose count 18.5/15.0. Average score (6.5)\n",
      "Win/lose count 7.0/3.0. Average score (6.083333333333333)\n",
      "Win/lose count 19.5/11.0. Average score (6.428571428571429)\n",
      "Win/lose count 11.5/8.0. Average score (6.0625)\n",
      "Win/lose count 16.0/14.0. Average score (5.611111111111111)\n",
      "Win/lose count 12.0/5.0. Average score (5.75)\n",
      "Win/lose count 19.0/10.0. Average score (6.045454545454546)\n",
      "Final score: 6.045454545454546\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_test = 11\n",
    "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.3)\n",
    "test_explore(agent_demon,env,epochs_test,prefix='demon_test_explore')\n",
    "HTML(display_videos('demon_test_explore10.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "name": "DQN_project_MVA.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
